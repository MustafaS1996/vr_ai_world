{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ddcb5b1-a2d7-460f-b096-585047c3db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e0514b-120b-420b-988c-ab395566ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/workspace/vr_ai_world/env/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbf7f5b-fee1-4e52-b76f-276232531490",
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = load_model('transmitter', device=device) \n",
    "model = load_model('text300M', device=device) \n",
    "diffusion = diffusion_from_config(load_config('diffusion')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d02fd-14e6-4142-9ccb-1d5a169e1571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f243552dab4a97870a28e83671aebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1 # this is the size of the models, higher values take longer to generate.\n",
    "guidance_scale = 15.0 # this is the scale of the guidance, higher values make the model look more like the prompt.\n",
    "prompt = \"a teddy bear\" # this is the prompt, you can change this to anything you want.\n",
    "\n",
    "latents = sample_latents(\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    model_kwargs=dict(texts=[prompt] * batch_size),\n",
    "    progress=True,\n",
    "    clip_denoised=True,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c195ee4-c7d8-425c-91f8-4eb21bb84c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_mode = 'nerf' # you can change this to 'stf'\n",
    "size = 64 # this is the size of the renders, higher values take longer to render.\n",
    "\n",
    "cameras = create_pan_cameras(size, device)\n",
    "for i, latent in enumerate(latents):\n",
    "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    display(gif_widget(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1886e13-d350-47a5-895a-2978d2fcc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of saving the latents as meshes.\n",
    "from shap_e.util.notebooks import decode_latent_mesh\n",
    "\n",
    "for i, latent in enumerate(latents):\n",
    "    t = decode_latent_mesh(xm, latent).tri_mesh()\n",
    "    with open(f'models/example_mesh_{i}.ply', 'wb') as f: # this is three-dimensional geometric data of model.\n",
    "        t.write_obj(f)\n",
    "    with open(f'models/example_mesh_{i}.obj', 'w') as f: # we will use this file to customize in Blender Studio later.\n",
    "        t.write_obj(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d779737-1937-4298-a40c-e1240d07cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flask flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be210aa1-3992-4bb0-b5fc-b37d9760cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shap_e.util.notebooks import decode_latent_mesh\n",
    "\n",
    "# def get_ai_3d_model(modeldesc):\n",
    "#     batch_size = 1 # this is the size of the models, higher values take longer to generate.\n",
    "#     guidance_scale = 15.0 # this is the scale of the guidance, higher values make the model look more like the prompt.\n",
    "#     prompt = modeldesc # this is the prompt, you can change this to anything you want.\n",
    "    \n",
    "#     latents = sample_latents(\n",
    "#         batch_size=batch_size,\n",
    "#         model=model,\n",
    "#         diffusion=diffusion,\n",
    "#         guidance_scale=guidance_scale,\n",
    "#         model_kwargs=dict(texts=[prompt] * batch_size),\n",
    "#         progress=True,\n",
    "#         clip_denoised=True,\n",
    "#         use_fp16=True,\n",
    "#         use_karras=True,\n",
    "#         karras_steps=64,\n",
    "#         sigma_min=1e-3,\n",
    "#         sigma_max=160,\n",
    "#         s_churn=0,\n",
    "#     )\n",
    "#     # Example of saving the latents as meshes.\n",
    "    \n",
    "#     for i, latent in enumerate(latents):\n",
    "#         t = decode_latent_mesh(xm, latent).tri_mesh()\n",
    "#         with open(f'models/{modeldesc}.ply', 'wb') as f: # this is three-dimensional geometric data of model.\n",
    "#             t.write_obj(f)\n",
    "#         with open(f'models/{modeldesc}.obj', 'w') as f: # we will use this file to customize in Blender Studio later.\n",
    "#             t.write_obj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1050b-827d-4bec-839c-47f4065051ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, send_from_directory\n",
    "from flask_cors import CORS\n",
    "\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes\n",
    "\n",
    "# Placeholder for your model and diffusion objects\n",
    "# model = None  # Replace with your actual model\n",
    "# diffusion = None  # Replace with your actual diffusion\n",
    "# xm = None  # Replace with your actual xm\n",
    "\n",
    "def get_ai_3d_model(modeldesc):\n",
    "    batch_size = 1\n",
    "    guidance_scale = 15.0\n",
    "    prompt = modeldesc\n",
    "\n",
    "    latents = sample_latents(\n",
    "        batch_size=batch_size,\n",
    "        model=model,\n",
    "        diffusion=diffusion,\n",
    "        guidance_scale=guidance_scale,\n",
    "        model_kwargs=dict(texts=[prompt] * batch_size),\n",
    "        progress=True,\n",
    "        clip_denoised=True,\n",
    "        use_fp16=True,\n",
    "        use_karras=True,\n",
    "        karras_steps=64,\n",
    "        sigma_min=1e-3,\n",
    "        sigma_max=160,\n",
    "        s_churn=0,\n",
    "    )\n",
    "\n",
    "    for i, latent in enumerate(latents):\n",
    "        t = decode_latent_mesh(xm, latent).tri_mesh()\n",
    "        obj_path = os.path.join('models', f'{modeldesc}.obj')\n",
    "        with open(obj_path, 'w') as f:\n",
    "            t.write_obj(f)\n",
    "        return obj_path\n",
    "\n",
    "@app.route('/model')\n",
    "def get_model():\n",
    "    modeldesc = request.args.get('description', default='a chocolate donut', type=str)\n",
    "    obj_path = get_ai_3d_model(modeldesc)\n",
    "    return send_from_directory(directory='models', path=f'{modeldesc}.obj')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
