<!DOCTYPE html>
<html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://aframe.io/releases/1.6.0/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/c-frame/aframe-physics-system@v4.2.2/dist/aframe-physics-system.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/c-frame/aframe-extras@7.5.0/dist/aframe-extras.min.js"></script>
  <script type="module">
    import { read_audio } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.1';
    window.read_audio = read_audio;
    //window.pipeline = pipeline
  </script>
</head>
<body>
  <a-scene>
    <!-- Textarea for Speech Output -->
    <a-entity
      id="textArea"
      geometry="primitive: plane; width: 2; height: 1"
      material="color: #AAA"
      position="0 1.6 -3"
      text="value: Build me a: "
      visible="false">
    </a-entity>

    <!-- Button for Starting/Stopping Speech Input -->
    <a-plane
      id="startButton"
      color="cyan"
      width="1"
      height="0.5"
      position="1.6 1.5 -3"
      text="value: Start Speech Input"
      cursor-listener obb-collider>
    </a-plane>

    <a-entity cursor="rayOrigin: mouse"></a-entity>
    <a-plane static-body rotation="-90 0 0" color="purple" scale="15 15 15" ></a-plane>
    <a-sky color="blue"></a-sky>
    <a-entity id="player">
      <a-camera id="head" wasd-controls look-controls-enabled keyboard-controls="mode: fps"></a-camera>
      <a-entity id="rightHand" laser-controls="hand: right" raycaster="objects: .clickable"></a-entity>
      <a-entity id="leftHand" laser-controls="hand: left" raycaster="objects: .clickable"></a-entity>
    </a-entity>

    <a-box dynamic-body color="red" scale="0.5 0.5 0.5" position="0.2 3 -2"></a-box>


    <a-light type="ambient" color="#888"></a-light>
    <a-light type="directional" color="#fff" intensity="0.5" position="0 1 1"></a-light>
  </a-scene>

  <script id="worker1" type="javascript/worker">
    import { pipeline, read_audio } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.1';
  
    self.pipeline = pipeline;

    self.onmessage = async function(event) {
      const audioFloat = event.data.floater;
    
      console.log(audioFloat)
    
      // Use the new transcriber API
      const transcriber = await self.pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');
      const output = await transcriber(audioFloat);
    
      // Post the transcription result back to the main thread
      self.postMessage({ text: output.text });
    };
    

  </script>
  
  <script>

    var blob = new Blob([
        document.querySelector('#worker1').textContent
      ], { type: "text/javascript" })

    // Note: window.webkitURL.createObjectURL() in Chrome 10+.
    var worker = new Worker(window.URL.createObjectURL(blob), { type: "module" });

    let isRecording = false; // Variable to track if speech recognition is active
    let recognizedText = ''; // Variable to store recognized speech
    let mediaRecorder = null; // MediaRecorder object
    let audioChunks = []; // Array to store audio chunks
    document.getElementById('startButton').classList.add('clickable');

    document.getElementById('startButton').addEventListener('click', async function () {
      const textArea = document.getElementById('textArea');
      textArea.setAttribute('visible', true); // Always show text area when button is clicked

      if (!isRecording) { // Start recording
        // Request permission to use the microphone
        try {
          const audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });

          // Initialize MediaRecorder
          mediaRecorder = new MediaRecorder(audioStream);
          
          // Clear any previous audio chunks
          audioChunks = [];
          
          // Handle data available event to store audio chunks
          mediaRecorder.ondataavailable = event => {
            audioChunks.push(event.data);
          };

          // Start recording
          mediaRecorder.start();
          console.log('Recording started');

          // Update button state
          isRecording = true;
          const button = document.getElementById('startButton');
          button.setAttribute('color', 'red');
          button.setAttribute('text', 'value', 'Stop Speech Input');
        } catch (error) {
          console.error('Error accessing microphone:', error);
        }
      } else { // Stop recording
        mediaRecorder.stop();

        // Handle stop event to process the audio
        // Handle stop event to process the audio
        mediaRecorder.onstop = () => {
                  console.log('Recording stopped, processing...');

                  // Create a Blob from the audio chunks
                  const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });

                  // Create a URL for the Blob
                  const url = URL.createObjectURL(audioBlob);

                  //floater = read_audio(url) 

                  // Read the audio
                  read_audio(url, 16000)
                    .then(floater => {
                      // Post the floater data to the web worker
                      worker.postMessage({ floater });

                      // Listen for messages from the worker
                      worker.onmessage = function(event) {
                        const output = event.data;

                        recognizedText = output.text; // Save recognized speech to variable
                        console.log('Recognized speech:', recognizedText);

                        // Update text entity with recognized speech
                        textArea.setAttribute('text', 'value', 'Build me a: ' + recognizedText);

                        loadModel(recognizedText);

                        // Revoke the Blob URL after processing
                        URL.revokeObjectURL(url);
                      };

                      worker.onerror = function(error) {
                        console.error('There was a problem with the worker:', error);
                      };
                    })
                    .catch(error => {
                      console.error('There was a problem with reading the audio:', error);
                    });

                  // Update button state
                  isRecording = false;
                  const button = document.getElementById('startButton');
                  button.setAttribute('color', 'green');
                  button.setAttribute('text', 'value', 'Start Speech Input');

                };
              }
    });


  // Handle messages from the worker
  worker.onmessage = function(event) {
    recognizedText = event.data.text; // Get the recognized text from the worker
    console.log('Recognized speech:', recognizedText);

    const textArea = document.getElementById('textArea');
    // Update text entity with recognized speech
    textArea.setAttribute('text', 'value', 'Build me a: ' + recognizedText);

    loadModel(recognizedText);
  };

    // Function to fetch the model description from the server and log it to the console
    function loadModel(description) {
      const url = `http://localhost:5000/model?description=${encodeURIComponent(description)}`; // URL of the model with query parameter

      fetch(url)
        .then(response => {
          if (!response.ok) {
            throw new Error('Network response was not ok ' + response.statusText);
          }
          return response.blob(); // Get the response as Blob
        })
        .then(blob => {
          const blobUrl = URL.createObjectURL(blob); // Create a Blob URL
          addModelToScene(blobUrl); // Add the model to the scene
        })
        .catch(error => {
          console.error('There was a problem with the fetch operation:', error);
        });
    }

    // Function to add the model to the scene
    function addModelToScene(blobUrl) {
      const sceneEl = document.querySelector('a-scene'); // Get the scene element
      const newEntity = document.createElement('a-entity'); // Create a new entity
      newEntity.setAttribute('obj-model', `obj: ${blobUrl}`); // Set the obj-model attribute with the Blob URL
      newEntity.setAttribute('position', getRandomPosition()); // Set a random position
      newEntity.setAttribute('class', 'clickable'); // Add clickable class
      newEntity.setAttribute('cursor-listener', ''); // Add cursor-listener attribute
      sceneEl.appendChild(newEntity); // Add the new entity to the scene
      sceneEl.flushToDOM(); // Refresh the scene


      newEntity.addEventListener('loaded', () => {
      console.log('Entity loaded and ready for manipulation');
      // Safely update properties here
        newEntity.setAttribute('dynamic-body', ''); // Add cursor-listener attribute
        newEntity.components['dynamic-body'].initComponent();

      });
    }

    // Function to generate a random position
    function getRandomPosition() {
      return `${Math.random() * 4 - 2} 1 ${Math.random() * 4 - 2}`;
    }

    // Debug code
    document.addEventListener('DOMContentLoaded', function () {
      const sceneEl = document.querySelector('a-scene');
      const clickableEls = document.querySelectorAll('.clickable'); // Select all clickable objects
      let currentDraggedEl = null; // Track the currently dragged element
      let textBox = document.createElement('a-box');

      function createBox(event, textinBox) {
        const clickedEl = event.target;
        const sceneEl = document.querySelector('a-scene');
        sceneEl.remove(textBox);

        // Create new box
        const newBox = document.createElement('a-box');
        newBox.setAttribute('position', {x: 0, y: 1, z: -5});
        newBox.setAttribute('color', '#FFC65D');
        newBox.setAttribute('scale', {x: 2, y: 2, z: 2});

        // Create text
        const text = document.createElement('a-text');
        text.setAttribute('value', ` ${textinBox}`);
        text.setAttribute('color', '#000');
        text.setAttribute('position', {x: -1, y: 0, z: 0.5});
        text.setAttribute('scale', {x: 4, y: 4, z: 4});

        newBox.appendChild(text); // Attach text to the new box

        textBox = newBox;
        sceneEl.appendChild(textBox); // Attach the new box to the scene
      }

      // Function to start dragging
      function startDrag(evt) {
        currentDraggedEl = evt.currentTarget; // Set the current element being dragged
        currentDraggedEl.classList.add('dragging'); // Optional: Add a class for styling if necessary
        createBox(event, `started`);
      }

      // Function to do the dragging
      function doDrag(evt) {
        if (currentDraggedEl && currentDraggedEl.classList.contains('dragging')) {
          const cursorEl = document.querySelector('a-cursor');
          const intersection = cursorEl.components.raycaster.getIntersection(currentDraggedEl);
          createBox(event, `dragging inside ` + currentDraggedEl.getAttribute('id'));
          if (intersection) {
            const point = intersection.point;
            currentDraggedEl.setAttribute('position', { x: point.x, y: point.y, z: currentDraggedEl.getAttribute('position').z });
          }
        }
      }

      // Function to end dragging
      function endDrag(evt) {
        if (currentDraggedEl) {
          currentDraggedEl.classList.remove('dragging'); // Optional: Remove the class if added
          currentDraggedEl = null; // Clear the currently dragged element
        }
      }

      // Attach event listeners to each clickable element
      clickableEls.forEach(el => {
        el.addEventListener('mousedown', startDrag);
      });

      // Attach moving and up listeners to the scene
      sceneEl.addEventListener('mousemove', doDrag);
      sceneEl.addEventListener('mouseup', endDrag);
    });
  </script>

</body>
</html>
